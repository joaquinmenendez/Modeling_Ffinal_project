---
title: "Final Project"
author: "Joaquin Menendez (jm622)"
date: "December 4, 2018"
output:

subtitle: 'Exploratory analysis and inferential statistics '
---
# Influence of Semantic Similarity and Stimulus Onset Asynchrony on Semantic Subliminal Processing 
> ### *Studies employing a masked priming paradigm have observed that subliminal stimuli could be processed on a semantic level.  Semantic categorization of a consciously perceived stimulus could be facilitated by the presentation of a former stimulus that was not consciously perceived (subliminal). This facilitation is usually measured as the reaction time employed to respond to a task. When this facilitation occurs between congruent pairs of stimuli (from the same category) and does not occur between incongruent pairs (from different categories) is called congruency priming effect. Two principal factors modulate the subliminal priming effect, the semantic similarity between stimuli and the SOA.  Semantic similarity refers to the similarity in meaning or overlap of features between two words. The greater the similarity, the bigger the facilitation. Another factor that modulates priming effect is the interval between the onset of the first stimulus and the onset of the second stimulus of the par (SOA: stimulus onset asynchrony), showing that the bigger the SOA, the lower priming effect. Despite the fact that these two phenomena have been extensively studied, it has not been studied the influence of semantic strength has not been studied together with SOA duration. The goal of this study is to observe if semantic relatedness (strongly and weakly related pairs) could modulate congruency priming effect duration. To evaluate this, both semantic relatedness (strong and weak) and SOA were manipulated in a subliminal semantic priming task.*

```{r,include=FALSE}
library(doBy)
library(ggplot2)
library(dplyr)
library(psycho)
library(car)
library(lmerTest)  #https://www.r-bloggers.com/how-to-do-repeated-measures-anovas-in-r/
library(psycho)
library(psych)
library(lme4)
library(knitr)
opts_chunk$set(fig.show = "hold")
setwd('C:/Users/joaqu/OneDrive/Escritorio/702 Modeling and Representation of Data/Modeling_final_project/PROYECTO SOA/')
PATH = 'C:/Users/joaqu/OneDrive/Escritorio/702 Modeling and Representation of Data/Modeling_final_project/PROYECTO SOA/'
load(file= paste0(PATH,'dfpriming_v4.Rda'))
#summary(dfpriming)
```

```{r include=FALSE}
# Assigning the correct types to data ----
dfpriming$Age[dfpriming$Age == '21 anos '] = 21
dfpriming$Sleep_hours[dfpriming$Sleep_hours == 'Mas de 7'] = 8

dfpriming$Num.Trial = as.numeric(levels(dfpriming$Num.Trial)[dfpriming$Num.Trial]) #Needed to remove the factor level
dfpriming$RT = as.numeric(levels(dfpriming$RT)[dfpriming$RT])# from factor to numeric
dfpriming$RT[dfpriming$RT == 0] <- NA

dfpriming$Prime_aparition_time = as.numeric(levels(dfpriming$Prime_aparition_time)[dfpriming$Prime_aparition_time])
dfpriming$Answer = as.numeric(levels(dfpriming$Answer)[dfpriming$Answer])

dfpriming$Age = as.numeric(dfpriming$Age) #to numeric
dfpriming$Sleep_hours =  as.numeric(dfpriming$Sleep_hours)

dfpriming$ID = as.factor(dfpriming$ID) #to factor
dfpriming$Neuro_A = as.factor(dfpriming$Neuro_A)
dfpriming$Medication_A=  as.factor(dfpriming$Medication_A)
dfpriming$Works_A=  as.factor(dfpriming$Works_A)
dfpriming$Gender = as.factor((dfpriming$Gender))

dfpriming$Age[is.na(dfpriming$Age)]<- 19 #one subject typed '19*' on the age field. 
dfpriming$correct_key = factor(dfpriming$correct_key, levels = c('rctrl','lctrl')) #converting to factor
dfpriming$Key_pressed = factor(dfpriming$Key_pressed, levels = c('rctrl','lctrl')) #converting to factor
dfpriming$Categoria = factor(dfpriming$Categoria, levels = c("nr","sra","sro","wra","wro" ))


#recoding related 
dfpriming$Relation = dfpriming$Categoria
levels(dfpriming$Relation)[levels(dfpriming$Relation)=="sra"] <- "SR"
levels(dfpriming$Relation)[levels(dfpriming$Relation)=="sro"] <- "SR"
levels(dfpriming$Relation)[levels(dfpriming$Relation)=="wra"] <- "WR"
levels(dfpriming$Relation)[levels(dfpriming$Relation)=="wro"] <- "WR"
dfpriming$Relation = factor(dfpriming$Relation, levels = c('nr', 'WR', 'SR'))
save(dfpriming, file = 'dfpriming_clean.Rda')
```


### Checking correct responses
```{r, fig.height= 8, collapse=T}
#Some exploratory metrics ----
summary(dfpriming)
```

```{r}
#lets explore by Correct Answer
dfpriming[dfpriming$Answer == '1',] %>% 
  group_by(SOA, Relation) %>%
  summarise(RT.mean = mean(RT), RT.sd = sd(RT))
```

### Checking that all subject answered more o less correctly
```{r}
all_answer <- dfpriming %>%
          group_by(ID,SOA) %>%
          count(Answer)
```

```{r, fig.height= 8}
ggplot2::ggplot(data = all_answer) + geom_point(mapping = aes(x= ID, y=n, color = Answer)) + coord_flip() + facet_wrap(~SOA, scales = 'free')+  theme_classic()
```

We can see that subjects 66_18_231, 233_8_25 and 233_20_38 shown a abnormal pattern of response. Asking to the experimenters they responded that this subjects misunderstood the instructions and answered with opposite keys. In other words, they answered to Animals Images with the "Object key" (right control) and with the "Animal Key" (left control) to the object images. The responses of this three subject were reverted.


```{r include=FALSE}
# We would replace this
dfpriming_corrected = dfpriming
dfpriming_corrected$Answer = as.factor(dfpriming_corrected$Answer)
index1 = which(dfpriming_corrected$Answer[dfpriming_corrected$ID == '66_18_231']== 1)
index0 = which(dfpriming_corrected$Answer[dfpriming_corrected$ID == '66_18_231']== 0)
dfpriming_corrected[dfpriming_corrected$ID == '66_18_231',]$Answer[index1] = '0'
dfpriming_corrected[dfpriming_corrected$ID == '66_18_231',]$Answer[index0] = '1'     

index1 = which(dfpriming_corrected$Answer[dfpriming_corrected$ID == '233_8_25']== 1)
index0 = which(dfpriming_corrected$Answer[dfpriming_corrected$ID == '233_8_25']== 0)
dfpriming_corrected[dfpriming_corrected$ID == '233_8_25',]$Answer[index1] = '0'
dfpriming_corrected[dfpriming_corrected$ID == '233_8_25',]$Answer[index0] = '1'  

index1 = which(dfpriming_corrected$Answer[dfpriming_corrected$ID == '233_20_38']== 1)
index0 = which(dfpriming_corrected$Answer[dfpriming_corrected$ID == '233_20_38']== 0)
dfpriming_corrected[dfpriming_corrected$ID == '233_20_38',]$Answer[index1] = '0'
dfpriming_corrected[dfpriming_corrected$ID == '233_20_38',]$Answer[index0] = '1'  
save(dfpriming_corrected, file = 'dfpriming_clean.Rda')
```

### Checking missing values
```{r, collapse= T}
# Usually for primming effects expriments missing values are not considered. And the focus is only on correct answers. 
# We will need to remove NA responses and the training sets.
# BUT FIRST WE WOULD PERFORM A QUICK ANALYSIS ON THE NA RESPONSE VALUES to see if there is an assymetry on the NA 's distribution.

dffinal = dfpriming_corrected[dfpriming_corrected$Num.Trial > 0,] #Delete training trials

NA_by_Categoria = summaryBy(Key_pressed~Categoria, data=dffinal[is.na(dffinal$Key_pressed),],FUN =  summary)
NA_by_Categoria[c(1,8)]
NA_by_Relation = summaryBy(Key_pressed~Relation, data=dffinal[is.na(dffinal$Key_pressed),],FUN =  summary)
NA_by_Relation[c(1,8)]
```

There is no evidence of preference of NA response given a specific Relationship. Given the low numbers of NAs we are going to use a 'classical experimental approach' and we are not going to study trials were subjects did not response.

```{r include=FALSE}
dffinal =  dffinal[!is.na(dffinal$RT),]
summary(dffinal)
save(dffinal, file= 'dffinal.Rda')
```


```{r removing outliers, include=FALSE}
# Preparing data for ANOVA ----
# THIS IS ONLY TO THE ANOVA ANALYSIS, FOR THE HIERARCHICAL MODEL THE DF IS GOING TO BE THE dffinal 

# According to Ortells (2016) the common proccedure is to delete subject's trials that are over and under 2.5 SD from subject's mean RT (for the correct Answers.
df_without_out = dffinal
rownames(df_without_out) <- seq(length=nrow(df_without_out)) # Reset the row numbers 
df_without_out = df_without_out[df_without_out$Answer == 1,] #Only chose the correct answers!!
df_without_out$outlier = NA #A common practice is to remove the outlier results

for (Id in levels(df_without_out$ID)){#print(ID)
  x = df_without_out[df_without_out$ID == Id,]
  mean = mean(x$RT)
  sd = sd(x$RT)
  outlier = (mean-2.5*sd) > x$RT | x$RT > (mean+2.5*sd)
  df_without_out$outlier[df_without_out$ID == Id] = outlier}
```

According to Ortells et.al (2016), the common procedure on subliminal priming experimen is to work with a dataset composed of a unique value per subject for every level of the independent variable (Relation). Wwe are going to create a dataset summarizing the 245 trials into only 3 (one per condition) and only for correct responses. The idea is to use this DF to perform an ANOVA and compare this results with the results of our multilevel model.

```{r include=FALSE}
df_without_out = df_without_out[df_without_out$outlier == FALSE,]  #Removing outliers

df_summarized <- df_without_out %>% #We do this to check some means and SD 
      group_by(ID,Relation,dprime, SOA, prelikert,similarity) %>%       # CHECK!!!! CAMBIO
        #summarize(RT = mean(RT)) %>%
        ungroup()
df_summarized$SOA = as.factor(df_summarized$SOA)
```

### Summary of variables by Group

```{r}
df_summarized %>% 
  group_by(SOA, Relation) %>%
  summarize(mean_RT = mean(RT), sd_RT= sd(RT))

df_summarized %>% 
  group_by(SOA) %>%
  summarise(mean_dprime = mean(dprime), sd_dprime= sd(dprime))

df_summarized %>% 
  group_by(SOA) %>%
  summarise(similarity.mean = mean(similarity), sd.similarity= sd(similarity))
```


```{r include=FALSE}
# SIMPLE Tables TO CHECK IF GROUPS ARE BALANCED
multiple_data = df_without_out %>% #We do this to check some VARIABELS AS AGE SLEEP 
      group_by(ID, SOA,Age, Sleep_hours , Gender, prelikert, dprime) %>%
        summarize(RT = mean(RT)) %>%
        ungroup()
multiple_data$SOA = as.factor(multiple_data$SOA)
```

```{r, collapse= T} 
#Age
psych::describe(multiple_data[multiple_data$SOA== 66,]$Age)
psych::describe(multiple_data[multiple_data$SOA== 150,]$Age)
psych::describe(multiple_data[multiple_data$SOA== 233,]$Age)
psych::describe(multiple_data[multiple_data$SOA== 317,]$Age)

```

```{r,collapse= T}
#Sleeping
psych::describe(multiple_data[multiple_data$SOA== 66,]$Sleep_hours)
psych::describe(multiple_data[multiple_data$SOA== 150,]$Sleep_hours)
psych::describe(multiple_data[multiple_data$SOA== 233,]$Sleep_hours)
psych::describe(multiple_data[multiple_data$SOA== 317,]$Sleep_hours)
```

```{r,collapse= T}
#Gender
summary(multiple_data[multiple_data$SOA== 66,]$Gender)
summary(multiple_data[multiple_data$SOA== 150,]$Gender)
summary(multiple_data[multiple_data$SOA== 233,]$Gender)
summary(multiple_data[multiple_data$SOA== 317,]$Gender)
```

Despite of some subtle differences product of the random groupping, groups seem to be balanced on Age, sleep hours and Gender. 

##### According to Ortells et. al (2016), to check if subjects did not conciously proccessed  the prime stimuli on the experimental task, the dprime mean of the group on the visibility test must not be different from 0. 
```{r include=FALSE}
#T-test FOR THE DPRIME VALUE ON THE VISIBILITY TEST AGAINST 0. THIS IS NECCESATY TO CLAIM THAT INDIVIDUALS DID NOT WATCHED THE PRIME.
df_summarized <- df_without_out %>% #We do this to check some means and SD and graph on the rest of the file
  #we are looking to summarize the RT of each subject, on each condition.
      group_by(ID,Relation,dprime, SOA, prelikert) %>%       # CHECK!!!! CAMBIO
        summarize(RT = mean(RT)) %>%
        ungroup()
df_summarized$SOA = as.factor(df_summarized$SOA)
nr = df_summarized[df_summarized$Relation == "nr",] # I choose one relation (because they are repeated)
```

```{r, collapse= T}
t.test(nr[nr$SOA == 66,]$dprime, mu=0)
t.test(nr[nr$SOA == 150,]$dprime, mu=0)
t.test(nr[nr$SOA == 233,]$dprime, mu=0)
t.test(nr[nr$SOA == 317,]$dprime, mu=0)
```

We have some problems! All the dprimes values are different to 0. We would like to remove some subjects, this would have as consequence the lose of several subjects, would made impossible the use of parametric stats and also reduce the statistical power.



Checking dprime differences among groups
```{r, collapse= T}
#ANOVA for dprimes
leveneTest(multiple_data$dprime, multiple_data$SOA, center = median) #Homogeneity
tapply(multiple_data$dprime, multiple_data$SOA, shapiro.test) 
aov_dprime = aov(dprime~SOA,data= multiple_data)
summary(aov_dprime)
TukeyHSD(aov_dprime)
psych::describe(multiple_data[multiple_data$SOA== 150,]$dprime)
psych::describe(multiple_data[multiple_data$SOA== 233,]$dprime)
psych::describe(multiple_data[multiple_data$SOA== 317,]$dprime)
```

Variables are homogeneous (Levene Test F = 2.0749, p = 0.1086), and groups follow a normal distribution (Shapiro Wilk test, ps > .05 for all groups). There is statistical evidence of a difference among dprime per group F(3,96)=22.29 p < .001.
The bigger the SOA, the bigger the dprime. It could be interpreted as the  increase of SOA  facilitates the conscious processing of the prime stimulus.


Checking Prelikert differences among groups
```{r, collapse= T}
leveneTest(multiple_data$prelikert, multiple_data$SOA, center = median) #Las variables son homogeneas
tapply(multiple_data$prelikert, multiple_data$SOA, shapiro.test) # Not NORMAL
kruskal.test(prelikert~SOA,data= multiple_data) #Need to use a Kruskall Wallis
pairwise.wilcox.test(multiple_data$prelikert, multiple_data$SOA, p.adjust.method = 'fdr') #The problem is between 150 and 317
psych::describe(multiple_data[multiple_data$SOA== 66,]$prelikert)
psych::describe(multiple_data[multiple_data$SOA== 150,]$prelikert)
psych::describe(multiple_data[multiple_data$SOA== 233,]$prelikert)
psych::describe(multiple_data[multiple_data$SOA== 317,]$prelikert)
```

Prelikert by SOA groups are homogeneous (Levene test  F = 0.1087, p = 0.9548) but not follow a normal distribution (Shapiro Wilk test, ps < .01). Given that reason, I decided to apply a non-parametric Kruskall Wallis. The Kruskall test show a statistical trend ($X^2$= 6.575, p = .079). The Wilcoxon rank sum test shows that there are no difference between groups. We could claim that there are no evidence of difference among groups for prelikert values.



```{r}
histogramRT<-ggplot(data = df_summarized, aes(x=dprime, fill=SOA))+
  labs(x="RT")+
  ggtitle("Density plot of dPrime")+
  geom_density(color= 'black') +
  stat_function(fun = dnorm, colour = "Black",linetype = 2,size = 1 ,args = list(mean=mean(df_summarized$dprime), sd=sd(df_summarized$dprime))) + facet_wrap(~SOA)  + theme_classic()
histogramRT

histogramRT<-ggplot(data = df_summarized, aes(x=prelikert, fill = SOA))+
  labs(x="RT")+
  ggtitle("Density plot of prelikert")+
  geom_density(color= 'black') +
  stat_function(fun = dnorm, colour = "Black",linetype = 2,size = 1, args = list(mean=mean(df_summarized$prelikert), sd=sd(df_summarized$prelikert))) + facet_wrap(~SOA)  + theme_classic()
histogramRT

```


Given this information we could affirm that there is statistical evidence to affirm that the different SOA interval has a differential effect over the conscious processing of the prime stimuli during the objective visibility test.
If we take in count the evidence of the subjective report,  there is no evidence to claim that the suggested processed deferentially the prime stimulus during the experimental task (priming task). Given that the attention has a crucial role on conscious processing, it could be that the short period of time (even the bigger SOA interval) combined with the focus on the processing of the target stimuli is interfering on the processing of the prime stimuli. 
This is coherent with JaÅ›kowski & Verleger (2007). They claim that for efficient masking of the prime, the prime-target interval had to be quite short (about 50 ms). 




```{r, fig.width= 9}
#Exploratory data  graphics -----------
ggplot(data = df_summarized) + geom_boxplot(aes(x=Relation, y=RT, color = Relation)) + facet_wrap(~SOA, ncol = 4)+  theme_classic() + labs(title='RT ~ Relation')

ggplot(data = df_summarized) + geom_boxplot(aes(x=SOA, y=dprime, color = SOA)) +  theme_classic() +labs(title='dprime ~ SOA')

ggplot(data = df_summarized) + geom_boxplot(aes(x=SOA, y=prelikert, color = SOA))+  theme_classic()+ labs(title='Prelikert ~ SOA')

#General linear relation
ggplot(data = df_summarized,aes(x=dprime, y=RT, color = Relation, fill = Relation)) + geom_point()+ geom_smooth(method = lm, alpha=0.2)  +  theme_classic() + labs(title='dprime ~ RT')

ggplot(data = df_summarized,aes(x=prelikert, y=RT, color = Relation, fill = Relation)) + geom_point()+ geom_smooth(method = lm, alpha=0.2)  +  theme_classic() + labs(title='RT ~ Prelikert')

# Linear relations by group
ggplot(data = df_summarized,aes(x=dprime, y=RT, color = Relation, fill = Relation)) + geom_point()+ geom_smooth(method = lm, alpha=0.2) + facet_wrap(~SOA) +  theme_classic() + labs(title='dprime ~ RT by SOA')

ggplot(data = df_summarized,aes(x=prelikert, y=RT, color = Relation, fill = Relation)) + geom_point()+ geom_smooth(method = lm, alpha=0.2) + facet_wrap(~SOA) +  theme_classic() + labs(title='Preliker ~ RT by SOA')
```



Checking distribution of RT
```{r}
#RESPONSE TIME AND SOA GROUPS ------
histogramRT<-ggplot(df_summarized, aes(x=RT, fill = SOA))+
  labs(x="RT")+
  ggtitle("Density plot of RT (untransformed)") +
  geom_density( color = 'black')+
  stat_function(fun = dnorm, colour = "Black" , linetype = 2,size = 1, args = list(mean=mean(df_summarized$RT), sd=sd(df_summarized$RT))) + facet_wrap(~SOA)  + theme_classic()
histogramRT
```
```{r}
#Checking assumptions
car::leveneTest(df_summarized$RT, df_summarized$SOA, center = median) #Not homogeneous
tapply(df_summarized$RT, df_summarized$SOA, shapiro.test) #Not normality
```

When we checked the normality on the RT variable for the treatment groups we observed that the groups are not homogeneous (Levene test F(3,296)= 8.956, p < .001) and also don't follow a normal distribution (Shapiro Walk test, ps < .05 for all groups)


Applyng transformations to the RT data.
```{r}
# Using logaritmic transformation
df_transf = df_summarized
df_transf$RT = log10(df_transf$RT+1)
#Checking distribution Response time
histogramRT<-ggplot(df_transf, aes(x=RT,  fill = SOA))+
  labs(x="RT")+
  ggtitle("Density plot of log(RT)")+
  geom_density(color = 'black')+
  stat_function(fun = dnorm, colour = "Black", linetype = 2,size = 1, args = list(mean=mean(df_transf$RT), sd=sd(df_transf$RT))) + facet_wrap(~SOA)  + theme_classic()
histogramRT #Not changes
```

```{r}
#Inverse transformation ----
df_inv = df_summarized
df_inv$RT = 1/df_inv$RT 
histogramRT<-ggplot(df_inv, aes(x=RT, fill = SOA))+
  labs(x="RT")+
  ggtitle("Density plot of Inverse tranformation(RT) ")+
  geom_density(color = 'black')+
  stat_function(fun = dnorm, colour = "Black", size = 1, linetype= 2, args = list(mean=mean(df_inv$RT), sd=sd(df_inv$RT))) + facet_wrap(~SOA)  + theme_classic() 
histogramRT
```
```{r}
#Check assumptions
car::leveneTest(df_inv$RT, df_inv$SOA, center = median) #Las variables  NO son homogeneas!!
tapply(df_inv$RT, df_inv$SOA, shapiro.test) #NO da normal!!!!

```

I tried to apply logarithmic and inverse transformation to the data in order to homogenize the data. Despite that the variance among groups remained different. The original intention was to realize a Mixed design ANOVA 4x3 where:

  |IV between|SOA|
  |IV within|Relation|
  |DV|RT|

Given the currents limitations, I would use a multilevel model for repeated measures. This model would allow to work with normally distributed data given the fact that it will not be necessary to average the RT of each subject per condition, allowing to work with all the trials of each subject. 
This would allow us to respond the answer of the role of the treatment group an the possible interactions with the semantic relatedness. 

Lastly, we would perform some non parametric test with every group individually. In order to do that, we are going to use the Friedman Test (in the markdown an alternative approach is mentioned).
```{R include=FALSE}
#LETS MAKE A NON PARAMETRIC ONE FACTOR  or friedman.test TO EVALUATE THE RELATEDNESS EFFECT ON EVERY GROUP 

df_summarized$Relation = factor(df_summarized$Relation, levels = c('nr','WR', 'SR'))
df_summarized$ID = as.character(df_summarized$ID)
```

```{R include=FALSE}
######### An alternative to the Friedman Test is to apply a rank to the VD and perform an ANOVA. Here it is a proof of concept

s66 =  df_summarized[df_summarized$SOA == '66',]
#No ranked
noranked66 = lmer(RT~Relation + (1|ID), data = s66)
anova(noranked66)
results <- psycho::get_contrasts(noranked66, "Relation")
print(results$means)
print(results$contrasts)
plot(residuals(noranked66) ~ s66$Relation)
plot(residuals(noranked66) ~ as.factor(s66$ID))

#Ranked 
rRT = rank(s66$RT)
ranked66 = lmer(rRT~Relation + (1|ID), data = s66)
anova(ranked66)
results <- psycho::get_contrasts(noranked66, "Relation")
print(results$means)
print(results$contrasts)
plot(residuals(ranked66) ~ s66$Relation)
plot(residuals(ranked66) ~ as.factor(s66$ID))

############
```



```{r, collapse=T}
# Friedman Test ----
friedman.test(RT ~ Relation|ID, data = df_summarized[df_summarized$SOA == '66',])  
friedman.test(RT ~ Relation|ID, data = df_summarized[df_summarized$SOA == '150',]) 
friedman.test(RT ~ Relation|ID, data = df_summarized[df_summarized$SOA == '233',])  
friedman.test(RT ~ Relation|ID, data = df_summarized[df_summarized$SOA == '317',])  
#dffinal %>% group_by(SOA, Relation) %>% summarise(meanRT = mean((RT)), sd = sd((RT)))
```

 Analysis show statistical evidence of difference by Relation between groups for SOA 66 ($X^2$ = 6.58, p = 0.03 ), SOA 150 ($X^2$ = 7, p = 0.03) and SOA 317 ($X^2$ = 8, p = 0.01), but no for SOA 233($X^2$ = 2.07 , p = 0.35)


```{r include=FALSE}
#Handler to plot the SE
datos = df_summarized%>% 
      group_by(SOA,Relation) %>% 
      summarise(mean = mean(RT), sd = sd(RT),se = sd(RT)/sqrt(n()) )%>%
        ungroup()
```


```{r}
 ggplot(data= datos, aes(x=Relation, y=mean, fill = Relation)) + geom_bar(position = 'dodge', stat = 'identity' ,color= 'black') + facet_wrap(~SOA) + theme_classic() + coord_cartesian(ylim = c(0.4, 0.6)) + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width = .075, colour ="black") + ylab('RT') + labs(title = 'RT by group')
```



```{r eval=FALSE, fig.width=10, include=FALSE}
#Other possible graphics
ggplot(data = df_summarized) + geom_point(aes(x=dprime, y=RT, color = Relation) , position = 'jitter') + facet_wrap(~SOA, ncol = 2) + theme_light() 
ggplot(data = df_summarized) + geom_point(aes(x=dprime, y=RT, color = SOA) , position = 'jitter') + facet_wrap(~Relation, ncol = 3) + theme_light() 
```














































