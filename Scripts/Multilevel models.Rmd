---
title: "Hierarchycal model"
author: "Joaquin Menendez (jm622)"
date: "November 27, 2018"
output: html_document
---

```{r}
library(doBy)
library(plyr)
library(ggplot2)
library(dplyr)
library(psycho)
library(lme4)
library(lattice)
#install.packages('corrplot')
library(corrplot)
library(psych)

setwd('C:/Users/joaqu/OneDrive/Escritorio/702 Modeling and Representation of Data/Modeling_final_project/PROYECTO SOA/')
load(file = 'dffinal.Rda')
summary(dffinal)
dffinal$Relation = factor(dffinal$Relation, levels = c('nr','WR', 'SR'))
dffinal$Answer = factor(dffinal$Answer, levels = c('1','0'))
dffinal$ID = as.character(levels(dffinal$ID)[dffinal$ID]) 
```

```{r}
table(dffinal$SOA) #The number of trials differ given the difference in the amount of subjects per group
#I care:
#  similarity rt
#  relation rt
#  soa rt
#  dprime rt
#  dprime soa
#  answer relation
#  TRIAL RT
#  Trial Correctas
plot(RT~similarity+prelikert+Relation+dprime+as.factor(SOA)+Num.Trial,data = dffinal)
plot(dprime~as.factor(SOA), data = dffinal)
#We definetively have an effect of SOA on dprime. We cannot observe this effect on RT

# RT~dprime seems to be slightly quadratic, but is not clear (maybe this is only observable for the correct answers)
# No clear effect of relation on RT (maybe this is only observable for the correct answers)
plot(dffinal$ID,dffinal$RT)
plot(dffinal$Answer,dffinal$Relation)
plot(dffinal$Answer, dffinal$RT)
#There is a slightly difference of correct answers depending on the relation. Subjects have more mistakes when relation is not related.
# There is no difference between RT for correct answer or slower. This could be due to the assymetry.
```

```{r}
#check correlations among the predictors to look for colinearity
cor(dffinal$prelikert,dffinal$similarity)
cor(dffinal$dprime,dffinal$similarity)
cor(dffinal$Num.Trial,dffinal$similarity)
cor(dffinal$prelikert,dffinal$dprime)
cor(dffinal$prelikert,dffinal$Num.Trial)
cor(dffinal$dprime,dffinal$Num.Trial)
fac_to_num = dffinal$Relation
fac_to_num = revalue(fac_to_num,c('nr' = 1, 'WR' = 2, 'SR' = 3))
fac_to_num = as.numeric(fac_to_num)
dffinal$Rel.num = fac_to_num
cor(fac_to_num,dffinal$similarity)  # GREAT!


cor.plot(dffinal[c(3,1,11,17,20,27,29)],stars = T)
corrplot(cor(dffinal[c(3,1,11,17,20,27,29)]),method = 'shade',title = 'Correlation plot')
```

```{r}
xyplot(RT ~ as.factor(SOA) | Answer, data = dffinal)
xyplot(RT ~ dprime | Answer, data = dffinal)
xyplot(RT ~ Relation | Answer, data = dffinal) #there is no clear effect of interaction
xyplot(RT ~ similarity | Answer, data = dffinal) #It could observe ainteraction between similarity and Answer
xyplot(RT ~ Num.Trial | Answer, data = dffinal) #It does not seem to be an effect of trial
xyplot(RT ~ dprime |as.factor(SOA) , data = dffinal)
xyplot(RT ~ ID | Relation, data= dffinal)

```

```{r}
# mean centering cuantitative trials  --- num.trial, similarity, dprime, prelikert
dffinal$c.Num.Trial = dffinal$Num.Trial - mean(dffinal$Num.Trial)
dffinal$c.similarity = dffinal$similarity - mean(dffinal$similarity)
dffinal$c.dprime = dffinal$dprime - mean(dffinal$dprime) 
dffinal$c.prelikert = dffinal$prelikert - mean(dffinal$prelikert)
```

```{r}
#lets run a silly linear model ------
mod1 = lm(RT~c.similarity+c.prelikert+Relation+c.dprime+ as.factor(SOA)+c.Num.Trial+ Answer + ID, data= dffinal)
summary(mod1)
#diagnostics
plot(y = mod1$residuals, x=dffinal$c.similarity, xlab = "Similarity", ylab = "Residual")
abline(0,0)

plot(y = mod1$residuals, x=dffinal$c.prelikert, xlab = "Likert", ylab = "Residual")
abline(0,0)

plot(y = mod1$residuals, x=dffinal$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)

plot(y = mod1$residuals, x=dffinal$c.Num.Trial, xlab = "Num. Trial", ylab = "Residual")
abline(0,0)

boxplot(mod1$residuals~dffinal$Answer, xlab = "Answer", ylab = "Residual")
abline(0,0)
boxplot(mod1$residuals~dffinal$SOA, xlab = "SOA", ylab = "Residual")
abline(0,0)

```

```{r}
plot(mod1)
```

```{r}
# Modelo logaritmico
# Lets check some transformations
dffinal$log.RT = log(dffinal$RT)
mod2 = lm(log.RT~c.similarity+c.prelikert+Relation+ c.dprime +  as.factor(SOA)+c.Num.Trial+ Answer + ID, data= dffinal)
summary(mod2)
plot(mod2)
plot(y = mod2$residuals, x=dffinal$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)
plot(y = mod2$residuals, x=dffinal$c.similarity, xlab = "Similarity", ylab = "Residual")
abline(0,0)

plot(y = mod2$residuals, x=dffinal$c.prelikert, xlab = "Likert", ylab = "Residual")
abline(0,0)

plot(y = mod2$residuals, x=dffinal$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)

plot(y = mod2$residuals, x=dffinal$c.Num.Trial, xlab = "Num. Trial", ylab = "Residual")
abline(0,0)

boxplot(mod2$residuals~dffinal$Answer, xlab = "Answer", ylab = "Residual")
abline(0,0)
boxplot(mod2$residuals~dffinal$SOA, xlab = "SOA", ylab = "Residual")
abline(0,0)

```

```{r}
# Modelo eliminadno outliers -----
df_without_out = dffinal

# mean centering cuantitative trials  --- num.trial, similarity, dprime, prelikert
df_without_out$c.Num.Trial = df_without_out$Num.Trial - mean(df_without_out$Num.Trial)
df_without_out$c.similarity = df_without_out$similarity - mean(df_without_out$similarity)
df_without_out$c.dprime = df_without_out$dprime - mean(df_without_out$dprime) 
df_without_out$c.prelikert = df_without_out$prelikert - mean(df_without_out$prelikert)

for (Id in levels(as.factor(df_without_out$ID))){#print(ID)
  x = df_without_out[df_without_out$ID == Id,]
  mean = mean(x$RT)
  sd = sd(x$RT)
  outlier = (mean-2.5*sd) > x$RT | x$RT > (mean+2.5*sd)
  df_without_out$outlier[df_without_out$ID == Id] = outlier}


df_without_out = df_without_out[df_without_out$outlier == FALSE,]  #Removing outliers
df_without_out$log.RT = log(df_without_out$RT)
mod3 = lm(log.RT~c.similarity+c.prelikert+Relation+ c.dprime +  as.factor(SOA)+c.Num.Trial+ Answer + ID, data= df_without_out)
plot(mod3)
summary(mod3)

plot(y = mod3$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)
plot(y = mod3$residuals, x=df_without_out$c.similarity, xlab = "Similarity", ylab = "Residual")
abline(0,0)

plot(y = mod3$residuals, x=df_without_out$c.prelikert, xlab = "Likert", ylab = "Residual")
abline(0,0)

plot(y = mod3$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)

plot(y = mod3$residuals, x=df_without_out$c.Num.Trial, xlab = "Num. Trial", ylab = "Residual")
abline(0,0)

boxplot(mod3$residuals~df_without_out$Answer, xlab = "Answer", ylab = "Residual")
abline(0,0)
boxplot(mod3$residuals~df_without_out$SOA, xlab = "SOA", ylab = "Residual")
abline(0,0)
# Los plot se ven mejores pero no parece haber demasiado ruido en mis datos.
```

```{r}
# MODELO sencillo -----
df.final = dffinal
# mean centering cuantitative trials  --- num.trial, similarity, dprime, prelikert
df.final$c.Num.Trial = df.final$Num.Trial - mean(df.final$Num.Trial)
df.final$c.similarity = df.final$similarity - mean(df.final$similarity)
df.final$c.dprime = df.final$dprime - mean(df.final$dprime) 
df.final$c.prelikert = df.final$prelikert - mean(df.final$prelikert)
mod4 = lm(log.RT~Relation+ c.dprime +  as.factor(SOA)+ Answer + ID, data= df.final)
plot(mod4)
summary(mod4)
plot(y = mod4$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)
plot(y = mod4$residuals, x=df_without_out$c.similarity, xlab = "Similarity", ylab = "Residual")
abline(0,0)

plot(y = mod4$residuals, x=df_without_out$c.prelikert, xlab = "Likert", ylab = "Residual")
abline(0,0)

plot(y = mod4$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)

plot(y = mod4$residuals, x=df_without_out$c.Num.Trial, xlab = "Num. Trial", ylab = "Residual")
abline(0,0)

boxplot(mod4$residuals~df_without_out$Answer, xlab = "Answer", ylab = "Residual")
abline(0,0)
boxplot(mod4$residuals~df_without_out$SOA, xlab = "SOA", ylab = "Residual")
abline(0,0)
#ME GUSTA ESTE!! VAMOS con este
```

```{r}
# MODELO interaccion dprime y SOA  La interaccion no tiene sentido-----   
mod5 = lm(log.RT~Relation+ c.dprime *  as.factor(SOA)+ Answer + ID, data= df.final)
plot(mod5)
summary(mod5)
plot(y = mod5$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)
plot(y = mod5$residuals, x=df_without_out$c.similarity, xlab = "Similarity", ylab = "Residual")
abline(0,0)

plot(y = mod5$residuals, x=df_without_out$c.prelikert, xlab = "Likert", ylab = "Residual")
abline(0,0)

plot(y = mod5$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)

plot(y = mod5$residuals, x=df_without_out$c.Num.Trial, xlab = "Num. Trial", ylab = "Residual")
abline(0,0)

boxplot(mod5$residuals~df_without_out$Answer, xlab = "Answer", ylab = "Residual")
abline(0,0)
boxplot(mod5$residuals~df_without_out$SOA, xlab = "SOA", ylab = "Residual")
abline(0,0)
```
```{r}
#MODELO SIN OUTLIERS y SIN RESPUESTAS INCORRECTAS!------
df_without_out = dffinal
df_without_out$outlier = NA
df_without_out = df_without_out[df_without_out$Answer == 1,] #Only chose the correct answers!!

# mean centering cuantitative trials  --- num.trial, similarity, dprime, prelikert
df_without_out$c.Num.Trial = df_without_out$Num.Trial - mean(df_without_out$Num.Trial)
df_without_out$c.similarity = df_without_out$similarity - mean(df_without_out$similarity)
df_without_out$c.dprime = df_without_out$dprime - mean(df_without_out$dprime) 
df_without_out$c.prelikert = df_without_out$prelikert - mean(df_without_out$prelikert)

for (Id in levels(as.factor(df_without_out$ID))){#print(ID)
  x = df_without_out[df_without_out$ID == Id,]
  mean = mean(x$RT)
  sd = sd(x$RT)
  outlier = (mean-2.5*sd) > x$RT | x$RT > (mean+2.5*sd)
  df_without_out$outlier[df_without_out$ID == Id] = outlier}


df_without_out = df_without_out[df_without_out$outlier == FALSE,]  #Removing outliers
df_without_out$log.RT = log(df_without_out$RT)
mod6 = lm(log.RT~Relation+ c.dprime +  as.factor(SOA)+ ID, data= df_without_out)
plot(mod6)
summary(mod6)

plot(y = mod6$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)
plot(y = mod6$residuals, x=df_without_out$c.similarity, xlab = "Similarity", ylab = "Residual")
abline(0,0)

plot(y = mod6$residuals, x=df_without_out$c.prelikert, xlab = "Likert", ylab = "Residual")
abline(0,0)

plot(y = mod6$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)

plot(y = mod6$residuals, x=df_without_out$c.Num.Trial, xlab = "Num. Trial", ylab = "Residual")
abline(0,0)

boxplot(mod6$residuals~df_without_out$Answer, xlab = "Answer", ylab = "Residual")
abline(0,0)
boxplot(mod6$residuals~df_without_out$SOA, xlab = "SOA", ylab = "Residual")
abline(0,0)
# Los plot se ven mejores pero no parece haber demasiado ruido en mis datos.
```

```{r}
#MODELO SIN OUTLIERS y SIN RESPUESTAS INCORRECTAS con INTERACCION! - La interaccion no tiene sentido-----  
df_without_out = dffinal
df_without_out$outlier = NA
df_without_out = df_without_out[df_without_out$Answer == 1,] #Only chose the correct answers!!

# mean centering cuantitative trials  --- num.trial, similarity, dprime, prelikert
df_without_out$c.Num.Trial = df_without_out$Num.Trial - mean(df_without_out$Num.Trial)
df_without_out$c.similarity = df_without_out$similarity - mean(df_without_out$similarity)
df_without_out$c.dprime = df_without_out$dprime - mean(df_without_out$dprime) 
df_without_out$c.prelikert = df_without_out$prelikert - mean(df_without_out$prelikert)

for (Id in levels(as.factor(df_without_out$ID))){#print(ID)
  x = df_without_out[df_without_out$ID == Id,]
  mean = mean(x$RT)
  sd = sd(x$RT)
  outlier = (mean-2.5*sd) > x$RT | x$RT > (mean+2.5*sd)
  df_without_out$outlier[df_without_out$ID == Id] = outlier}


df_without_out = df_without_out[df_without_out$outlier == FALSE,]  #Removing outliers
df_without_out$log.RT = log(df_without_out$RT)
mod7 = lm(log.RT~Relation+ c.dprime * as.factor(SOA)+ ID, data= df_without_out)
plot(mod7)
summary(mod7)

plot(y = mod7$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)
plot(y = mod7$residuals, x=df_without_out$c.similarity, xlab = "Similarity", ylab = "Residual")
abline(0,0)

plot(y = mod7$residuals, x=df_without_out$c.prelikert, xlab = "Likert", ylab = "Residual")
abline(0,0)

plot(y = mod7$residuals, x=df_without_out$c.dprime, xlab = "dPrime", ylab = "Residual") # maybe A quadratic relation
abline(0,0)

plot(y = mod7$residuals, x=df_without_out$c.Num.Trial, xlab = "Num. Trial", ylab = "Residual")
abline(0,0)

boxplot(mod7$residuals~df_without_out$Answer, xlab = "Answer", ylab = "Residual")
abline(0,0)
boxplot(mod7$residuals~df_without_out$SOA, xlab = "SOA", ylab = "Residual")
abline(0,0)
```


```{r}
#HIERARCHYCAL MODEL simple, without similarity ----
# Subject as a random effect
h.mod1 = lmer(log.RT ~ Relation + as.factor(SOA) + dprime  + (1 | ID), data = dffinal) 
summary(h.mod1)

#look at the intercepts (and the common slope) for each ID
coef(h.mod1)

#these equal the fixed effects plus the random effect
fixef(h.mod1)
ranef(h.mod1)
```

```{r}
# Hierarchycal simple pero sin relation , en su lugar similarity-----
h.mod2 = lmer(log.RT ~  similarity + as.factor(SOA) + dprime  +  (1 | ID), data = dffinal) 
summary(h.mod2)

#look at the intercepts (and the common slope) for each ID
coef(h.mod2)

#these equal the fixed effects plus the random effect
fixef(h.mod2)
ranef(h.mod2)

anova(h.mod1,h.mod2)
```

```{r}
# Hierarchycal simple pero con Relation y similarity-----
h.mod3 = lmer(log.RT ~ Relation +  similarity + as.factor(SOA) + dprime  +  (1 | ID), data = dffinal) 
summary(h.mod3)

anova(h.mod1,h.mod3) # Model 3 is slightly better than 1
anova(h.mod2,h.mod3)
```


```{r}
#HIERARCHYCAL MODEL with ID as random effects
h.mod4 = lmer(log.RT ~  Relation + dprime +  as.factor(SOA) +  (similarity| ID), data = dffinal) #REALLY LIKE THIS MODEL!!!
summary(h.mod4)
coef(h.mod4)

anova(h.mod1,h.mod4)
anova(h.mod2,h.mod4)
anova(h.mod3,h.mod4)  #Marginal tendency!!! The four is the fucking winner
```

```{r}
h.mod4 = lmer(log.RT ~  Relation + dprime +  as.factor(SOA) +  (similarity| ID), data = dffinal) #REALLY LIKE THIS MODEL!!!
summary(h.mod4)
coef(h.mod4)

anova(h.mod1,h.mod4)
anova(h.mod2,h.mod4)
anova(h.mod3,h.mod4)  #Marginal tendency!!! The four is the fucking winner
```




