---
title: "SOA 66"
output: html_document
---

#chequea que todos los archivos subidos correspondan al mismo estímulo
```{r chequeo estimulo, include=FALSE}
#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66/"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv. Importante fill=True
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de visualización del prime que van de la fila 322 a 450
  tipoestimulo<- resultado.crudo[29,]

})


#une para todos los sujetos la parte de  visualización subjetiva en un solo dataFrame
tipo.estimulo<-Reduce(function(x,y){merge(x,y,all=TRUE)}, data.set)
tipo.estimulo
```


#chequea antcedentes neurologicos
```{r antecedentes, include=FALSE}
#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv. Importante fill=True
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de visualización del prime que van de la fila 322 a 450
  tipoestimulo<- resultado.crudo[5,]

})


#une para todos los sujetos la parte de  visualización subjetiva en un solo dataFrame
antecedentes<-Reduce(function(x,y){merge(x,y,all=TRUE)}, data.set)
antecedentes
```

#Este levanta y genera un DF con todos los TR de las respuestas correctas
```{r DataSets original, include=FALSE}
#llamo librerías
library(ggplot2)
library(psych)

#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv 
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de Priming enmascarado que van de la fila 41 a la 296
  resultado.cortado<- resultado.crudo[41:296,]
  
  #se queda solo con las respuestas correctas y las columnas de interés
  resultado.correctas<-subset(resultado.cortado, resultado.cortado[,3] == 1, select=c("NumSujeto","Trial", "Tiempo", "Categoria"))
 
})

#une los TR de NR de todos los sujetos en un solo dataFrame
correctas.total<- Reduce(function(x,y) {merge(x,y,all=TRUE)}, data.set) 
  #convierte en numeric a los TR sino los toma como Factors. Primero se convierten character y después en numeric 
  correctas.total$Tiempo<-as.numeric(as.character(correctas.total$Tiempo))
  
  #Arroja la media, sd, etc de la muestra
  describe(correctas.total$Tiempo)
  
  #histograma de los tiempos de reacción CON Outliers 
histogramTotal<-ggplot(correctas.total, aes(x=Tiempo))+
  labs(x="Tiempo de reacción")+
  ggtitle("Histograma de tiempos de reacción CON outliers")+
  geom_histogram(binwidth = 0.005, colour= "tomato4", fill="tomato3")
histogramTotal
```

#Este levanta y genera un DF con todos los TR de las respuestas incorrectas
```{r DataSets incorrectas, include=FALSE}
#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv 
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de Priming enmascarado que van de la fila 41 a la 296
  resultado.cortado<- resultado.crudo[41:296,]
  
  #se queda solo con las respuestas correctas y las columnas de interés
  resultado.incorrectas<-subset(resultado.cortado, resultado.cortado[,3] == 0, select=c("NumSujeto","Trial", "Tiempo", "Categoria"))
 
})

#une los TR de NR de todos los sujetos en un solo dataFrame
incorrectas.total<- Reduce(function(x,y) {merge(x,y,all=TRUE)}, data.set)

```

#LEvanta los DF y le quita los outliers por sujeto. Y divide en 3 df por condición SR WR y NR
```{r Outliers, include=FALSE}
#llamo librerrías
library(ggplot2)
library(psych)

#working directory, donde se guardan los graficos
setwd("C:/Users/Profe/Google Drive/Análisis Datos Priming")

#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv 
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de Priming enmascarado que van de la fila 41 a la 296
  resultado.cortado<- resultado.crudo[41:296,]
  
  #se queda solo con las respuestas correctas y las columnas de interés
  resultado.correctas<-subset(resultado.cortado, resultado.cortado[,3] == 1, select=c("NumSujeto","Trial", "Tiempo", "Categoria", "Prime", "Target"))
  
  #convierte en numeric a los TR sino los toma como Factors. Primero se convierten character y después en numeric 
  resultado.correctas$Tiempo<-as.numeric(as.character(resultado.correctas$Tiempo))
  resultado.correctas$Trial<-as.numeric(as.character(resultado.correctas$Trial))
  #elimina outliers que estén a mas de 2.5 SD de la media de cada Sujeto en respuestas correctas.
  sinOutliers <- subset(resultado.correctas, resultado.correctas[,3] > mean(resultado.correctas[,3])-2.5*sd(resultado.correctas[,3]) & resultado.correctas[,3] < mean(resultado.correctas[,3])+2.5*sd(resultado.correctas[,3]))
})

#une los TR de NR de todos los sujetos en un solo dataFrame
total.Sinos<- Reduce(function(x,y) {merge(x,y,all=TRUE)}, data.set)

meanTotal<-aggregate(total.Sinos$Tiempo, by=list(Sujetos = total.Sinos$NumSujeto), mean)

#porcentaje de data cortada por outliers
rateoutliers <- (length(correctas.total$Tiempo)-length(total.Sinos$Tiempo))/length(correctas.total$Tiempo)
#crea DF para correctas Strong Related
correctasSR<- subset(total.Sinos,total.Sinos[,4] == "sra" |total.Sinos[,4] == "sro" )

#crea DF para correctas Weakly Related
correctasWR<- subset(total.Sinos,total.Sinos[,4] == "wra" |total.Sinos[,4] == "wro" )

#crea DF para correctas Not Related
correctasNR<- subset(total.Sinos,total.Sinos[,4] == "nr")

#Arroja la media, sd, etc de la muestra
describe(total.Sinos$Tiempo)

#histograma de los tiempos de reacción sin Outliers 
histogramSinos<-ggplot(total.Sinos, aes(x=Tiempo))+
  labs(x="Tiempo de reacción")+
  ggtitle("Histograma de tiempos de reacción sin outliers")+
  geom_histogram(binwidth = 0.01, colour= "deepskyblue4", fill="deepskyblue")
plot(histogramSinos)

qqplot <- qplot(sample= total.Sinos$Tiempo, stat = "qq")
qqplot



```
#Información del set.Respuestas COrrectas, Incorrectas, Descartadas outliers
```{r %de respuestas}
##*porcentaje de respuestas incorrectas*
percentage.incorrects <- NROW(incorrectas.total)/(NROW(correctas.total)+NROW(incorrectas.total))
percentage.incorrects

##porcentaje de respuestas outliers correctas, comparadas con el total de correctas
percentage.outliers <- NROW(total.Sinos)/(NROW(correctas.total)+NROW(incorrectas.total))
percentage.outliers

##
meanTotal<-aggregate(total.Sinos$Tiempo, by=list(Sujetos = total.Sinos$NumSujeto), mean)
outlier <- (mean(meanTotal$x) + 2.5*sd(meanTotal$x))
meanTotal[which(meanTotal$x > outlier),1]



```
#Este transforma los RT con log e inv
```{r transforma los RT en log10 e inv}
#llamo librerrías
library(ggplot2)
library(psych)

#Tranforma con log10 el tiempo del DF correctas.SR 
logSR<-correctasSR
logSR$Tiempo<-log10(logSR$Tiempo+1) 

#Tranforma con log10 el tiempo del DF correctas.WR 
logWR<-correctasWR
logWR$Tiempo<-log10(logWR$Tiempo+1) 

#Tranforma con log10 el tiempo del DF correctas.NR 
logNR<-correctasNR
logNR$Tiempo<- log10(logNR$Tiempo+1) 

log_total <- total.Sinos
log_total$Tiempo<- (log10(log_total$Tiempo+1))

describe(log_total)
#desnsity graph con curva normal para ver normalidad
histogramLog<-ggplot(log_total, aes(x=Tiempo))+
  labs(x="Tiempo de reacción")+
  ggtitle("Histograma de tiempos de reacción logaritmizados")+
  geom_density( colour= "cyan4", fill="cyan1")+
  stat_function(fun = dnorm, colour = "Red", args = list(mean=mean(log_total$Tiempo), sd=sd(log_total$Tiempo)))
histogramLog
ggsave("density  logartimizado con normal.png")
#qqplot para ver normalidad. Cuanto más diagonal más normal es
qqplotlog <- qplot(sample= log_total$Tiempo, stat = "qq")
qqplotlog
ggsave("qqplot logartimizado.png")



#total.sinos transformado por la reciproca
inv_total <- total.Sinos
inv_total$Tiempo<- (1/(inv_total$Tiempo))
describe(inv_total)

invSR<-correctasSR
invSR$Tiempo<-1/(invSR$Tiempo) 

#Tranforma con inv10 el tiempo del DF correctas.WR 
invWR<-correctasWR
invWR$Tiempo<-1/(invWR$Tiempo) 

#Tranforma con inv10 el tiempo del DF correctas.NR 
invNR<-correctasNR
invNR$Tiempo<- 1/(invNR$Tiempo)

#desnsity graph con curva normal para ver normalidad
histograminv<-ggplot(inv_total, aes(x=(Tiempo)))+
  labs(x="Tiempo de reacción")+
  ggtitle("Histograma de tiempos de reacción transformación inversa")+
  geom_density( colour= "chartreuse4", fill="chartreuse")+
  stat_function(fun = dnorm, colour = "Red", args = list(mean=mean(inv_total$Tiempo), sd=sd(inv_total$Tiempo)))
print(histograminv)

#qqplot para ver normalidad. Cuanto más diagonal más normal es
qqplotinv<- qplot(sample= inv_total$Tiempo, stat = "qq")
qqplotinv

library(car)
qqp(inv_total[,3],"norm")
```


#Promedia los TR para cada sujeto para las 3 condiciones.
```{r Promedio y SD por sujeto}

library(ggplot2)
library(matrixStats)
library(reshape)
#Media y SD de SR
meanSRxSujeto<-aggregate(correctasSR$Tiempo, by=list(Sujetos = correctasSR$NumSujeto), mean)
#Media y SD de WR
meanWRxSujeto<-aggregate(correctasWR$Tiempo, by=list(Sujetos = correctasWR$NumSujeto),FUN = mean, simplify = TRUE)
#Media y SD de NR
meanNRxSujeto<-aggregate(correctasNR$Tiempo, by=list(Sujetos = correctasNR$NumSujeto),FUN = mean, simplify = TRUE)
#Une las 3 medias por sujetos en un solo DF
meansxSujetos<- cbind(meanSRxSujeto, meanWRxSujeto$x, meanNRxSujeto$x)
colnames(meansxSujetos) <- c("Sujetos", "SR", "WR ", "NR")


#junta todas las condiciones en una columna de forma que es legible por el programa para graficar o ANOVA. Tiene que ser Long no wide
Tr_melt_SOA_66 <- melt(meansxSujetos, id=c("Sujetos"))
colnames(Tr_melt_SOA_66)<-c("Sujetos", "relacion", "RT")

describe(correctasSR$Tiempo)
describe(correctasWR$Tiempo)
describe(correctasNR$Tiempo)




#Media de SR con log
invMeanSRxSujeto<-aggregate(invSR$Tiempo, by=list(Sujetos = invSR$NumSujeto), mean)
#Media de WR con inv
invMeanWRxSujeto<-aggregate(invWR$Tiempo, by=list(Sujetos = invWR$NumSujeto),FUN = mean, simplify = TRUE)
#Media de NR con inv
invMeanNRxSujeto<-aggregate(invNR$Tiempo, by=list(Sujetos = invNR$NumSujeto),FUN = mean, simplify = TRUE)
#Une las 3 medias por sujetos en un solo DF
invMeans_SOA_66<-cbind(invMeanSRxSujeto, invMeanWRxSujeto$x, invMeanNRxSujeto$x)
colnames(invMeans_SOA_66) <- c("Sujetos", "Strong Related", "Weakly Related", "Not Related")

#meltea invTr para poder graficar anova etc. Tiene que estar long no wide
invTr_melt_SOA_66 <- melt(invMeans_SOA_66, id=c("Sujetos"))
invTr_melt_SOA_66$Sujetos<-as.character(invTr_melt_SOA_66$Sujetos)
colnames(invTr_melt_SOA_66) <- c("Sujetos", "relacion", "RT")


``` 


#Gráficos de todo tipo.
```{R Gráfico}
#working directory, donde se guardan los graficos
#setwd("C:/Users/Profe/Google Drive/Análisis Datos Priming")
#llamo librerías
library(ggplot2)
library(psych)
library(reshape)

#armo matriz para graficar. Calculando yo manuealmente la media y el standard error of the mean
mean<-aggregate(Tr_melt_SOA_66$RT, by = list(relacion = Tr_melt_SOA_66$relacion), mean)
sd <- aggregate(Tr_melt_SOA_66$RT, by = list(relacion = Tr_melt_SOA_66$relacion), sd)
length<-aggregate(Tr_melt_SOA_66$RT, by = list(relacion = Tr_melt_SOA_66$relacion), length)
se<- sd$x/sqrt(length$x)
GraficoTr_SOA_66<-cbind(mean, se)
rm(mean, sd, length, se)

#gráfico de barra. De TR sin transformar
bars <- ggplot(GraficoTr_SOA_66, aes(x=relacion, y=x ))+
  coord_cartesian(ylim = c(0.46, 0.555))+
  geom_col(fill =c("gray48", "gray68", "gray87"), colour = "black", width = 0.5)+
  geom_errorbar(position = position_dodge(width = NULL),aes(ymin=x-se, ymax=x+se), width = .075, colour ="black")+
  annotate('text', label= '*', x= 2, y= 0.552, size= 5) +
  annotate('text', label= '**', x= 2.5, y= 0.542, size= 5) +
  geom_segment(aes(x= 1, y= (0.55), xend= 3, yend= 0.55), colour="black")+
  geom_segment(aes(x= 2, y= (0.54), xend= 3, yend= 0.54), colour="black")+
  geom_segment(aes(x= 1, y= (0.55), xend= 1, yend= 0.545), colour="black")+
  geom_segment(aes(x= 3, y= (0.55), xend= 3, yend= 0.545), colour="black")+
  geom_segment(aes(x= 2, y= (0.54), xend= 2, yend= 0.535), colour="black")+
  geom_segment(aes(x= 3, y= (0.54), xend= 3, yend= 0.535), colour="black")+
labs(x="Relación entre Prime-Target", y="Tiempos de Reacción (s)", colour = "black")+
  theme_classic()+
  theme(axis.text=element_text(colour="black", size=8, face="bold"), axis.title=element_text(size=8,face="bold"))
  
plot(bars)
ggsave("barras relación SOA_66.jpg",width = 3, height = 3)

#gráfico de los TR sin transformar para las 3 condicioens x sujeto
scatterSujetos <- ggplot(Tr_melt_SOA_66, aes(x=Sujetos, y=RT, colour=relacion))+
  labs(x="Número de Sujeto", y="Tiempo de reacción")+
  ggtitle("Medias para condiciones de relación semántica por sujeto")+
  geom_point()+
  scale_x_continuous(breaks = seq(from = 1, to=35, by=1))
plot(scatterSujetos)
ggsave("distribución por sujeto por condicion.png")

#gráfico boxplot o de tallo hoja. De TR sin transformar
boxplot<-ggplot(Tr_melt_SOA_66, aes(x=relacion, y=RT))+
  labs(x="Relación Semántica", y="Tiempo de reacción")+
  ggtitle("Medias para condiciones de relación semántica por sujeto")+
  geom_boxplot(fill="brown2")
plot(boxplot)                 
#bloxplot para los transformados con inv
invBoxplot<-ggplot(invTr_melt_SOA_66, aes(x=relacion, y=RT))+
  labs(x="Relación Semántica", y="Tiempo de reacción")+
  ggtitle("Medias para condiciones de relación semántica por sujeto")+
  geom_boxplot(fill="brown")
invBoxplot

```


#ANOVA medidas repetidas
```{R ANOVA}
library(ez); library(ggplot2); library(multcomp); library(nlme); library(pastecs); library(reshape); library(WRS2)


#normalidad Shapiro-Wilk
shapiro.test(invTr_melt_SOA_66$RT)
#contrastes para la variable Relacion Semantica. Contrasta Fuerte y debil contra No, y despues fuerte y debil entre sí.
#contrasts(invTr_melt_SOA_66)<- cbind(c(1,1,-2), c(1,-1,0))

library(nlme)
#armado de los modelos para el anova como modelo lineal general
#modelo para RT solo
modelRT1<- lme(RT~1, random=~1|Sujetos, data=invTr_melt_SOA_66, method="ML")
#modelo RT con Relacion
modelRelacion1<-lme(RT~relacion, random=~1|Sujetos/relacion, data=invTr_melt_SOA_66, method="ML")
anova(modelRT1, modelRelacion1)
anova(modelRelacion1)



#anova con ezANOVA, más simple
anova<-ezANOVA(data=invTr_melt_SOA_66, dv= RT, wid= .(Sujetos), within=relacion, detailed = TRUE, type = 2)
anova

#tuckey post hoc!!! Necesita un modelo lineal.
library(multcomp)
posthocs <- glht(modelRelacion1, linfct = mcp(relacion = "Tukey"))
summary(posthocs)

#bonferroni post hoc
pairwise.t.test(invTr_melt_SOA_66$RT, invTr_melt_SOA_66$relacion, paired = TRUE, p.adjust.methods = "bonferroni")

```



#condiciones por bloques
```{R bloques, eval=FALSE, include=FALSE}

library(psych)
library(reshape)

#Promedia cada bloque de SR por bloque por sujeto. Primero subsetea el df grande diviendolo por bloques. Y despues al subset de cada bloque lo promedia por sujeto, y une todo en un DF
bloque.Sr <- cbind(aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "sra" |total.Sinos[,4] == "sro")&(total.Sinos[,2] <= 64), select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,2:3], aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "sra" |total.Sinos[,4] == "sro")&(total.Sinos[,2] > 64 & total.Sinos[,2] <= 128), select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3],
aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "sra" |total.Sinos[,4] == "sro")&(total.Sinos[,2] > 128 & total.Sinos[,2] <= 192),select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3],
aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "sra" |total.Sinos[,4] == "sro")&(total.Sinos[,2] > 192 & total.Sinos[,2] <= 256),select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3]) 
#Nombras las columnas del DF 
colnames(bloque.Sr)<-c("NumSujeto", "Bloque 1", "Bloque 2", "Bloque 3", "Bloque 4")
#melt Bloques SR
bloqueSrMelt <- cbind("strong related", melt(bloque.Sr, id=c("NumSujeto")))
colnames(bloqueSrMelt) <- c("RelacionSemantica", "NumSujeto", "Bloque", "ReactionTimes")

#Promedia cada bloque de Weakly Related por bloque por sujeto. Primero subsetea el df grande diviendolo por bloques. Y despues al subset de cada bloque lo promedia por sujeto, y une todo en un DF
bloque.Wr <- cbind(aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "wra" |total.Sinos[,4] == "wro")&(total.Sinos[,2] <= 64), select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,2:3], aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "wra" |total.Sinos[,4] == "wro")&(total.Sinos[,2] > 64 & total.Sinos[,2] <= 128), select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3],
aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "wra" |total.Sinos[,4] == "wro")&(total.Sinos[,2] > 128 & total.Sinos[,2] <= 192),select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3],
aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "wra" |total.Sinos[,4] == "wro")&(total.Sinos[,2] > 192 & total.Sinos[,2] <= 256),select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3]) 
#Nombras las columnas del DF 
colnames(bloque.Wr)<-c("NumSujeto", "Bloque 1", "Bloque 2", "Bloque 3", "Bloque 4")
#melt Bloques WR
bloqueWrMelt <- cbind("weakly related", melt(bloque.Wr, id=c("NumSujeto")))
colnames(bloqueWrMelt) <- c("RelacionSemantica", "NumSujeto", "Bloque", "ReactionTimes")

#Promedia cada bloque de Not Related por bloque por sujeto. Primero subsetea el df grande diviendolo por bloques. Y despues al subset de cada bloque lo promedia por sujeto, y une todo en un DF
bloque.Nr <- cbind(aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "nr")&(total.Sinos[,2] <= 64), select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,2:3],                    aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "nr")&(total.Sinos[,2] > 64 & total.Sinos[,2] <= 128), select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3],                  aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "nr")&(total.Sinos[,2] > 128 & total.Sinos[,2] <= 192),select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3],
aggregate(a<-subset(total.Sinos,(total.Sinos[,4] == "nr")&(total.Sinos[,2] > 192 & total.Sinos[,2] <= 256),select = c("NumSujeto", "Tiempo")), by=list(NumSujetos = a$NumSujeto), mean)[,3]) 
#Nombras las columnas del DF 
colnames(bloque.Nr)<-c("NumSujeto", "Bloque 1", "Bloque 2", "Bloque 3", "Bloque 4")
#melt Bloques WR
bloqueNrMelt <- cbind("not related",melt(bloque.Nr, id=c("NumSujeto")))
colnames(bloqueNrMelt) <- c("RelacionSemantica", "NumSujeto", "Bloque", "ReactionTimes")

#junto todos los bloques
bloques_juntos<-rbind(bloqueSrMelt,bloqueWrMelt,bloqueNrMelt)
describe(bloques_juntos)
#Para ver la media de RT de cada bloque
bloques <- rbind(bloque.Sr,bloque.Wr,bloque.Nr)
describe(bloques$`Bloque 1`)
describe(bloques$`Bloque 2`)
describe(bloques$`Bloque 3`)
describe(bloques$`Bloque 4`)

mean<-aggregate(bloques_juntos$ReactionTimes, by = list(RelacionSemantica = bloques_juntos$RelacionSemantica, Bloque = bloques_juntos$Bloque), mean)
sd <- aggregate(bloques_juntos$ReactionTimes, by = list(RelacionSemantica = bloques_juntos$RelacionSemantica, Bloque = bloques_juntos$Bloque), sd)
length<-aggregate(bloques_juntos$ReactionTimes, by = list(RelacionSemantica = bloques_juntos$RelacionSemantica, Bloque = bloques_juntos$Bloque), length)
se<- sd$x/sqrt(length$x)
Graficobloque<-cbind(mean, se)
rm(mean, sd, length, se)

library(ggplot2)
barblocks<- ggplot(Graficobloque, aes(x = Bloque, y =x, fill = RelacionSemantica))+
  coord_cartesian(ylim = c(0.55, 0.7))+
  geom_col( colour = "black", width = 0.5, position = "dodge")+
  geom_errorbar(aes(ymin=x-se, ymax=x+se), width = .075, colour ="black", position = "dodge")+
  scale_fill_manual(values = c("gray48", "gray68", "gray87"), guide=FALSE)+
  guides(fill = guide_legend(reverse=TRUE))+
  labs(x="Bloques", y="Tiempos de Reacción (ms)", fill = "Relación semántica")+
  theme_classic()+
  theme(axis.text=element_text(colour="black", size=4), axis.title=element_text(size=6,face="bold"))
  
barblocks
ggsave("barras relación ambos estímulos por bloque.png")



#transforma por la inversa los datos de reactin times, porque me había olvidado y sino no puedo hacer anova. Lo hago acá para que el grafico se haga con RT intactos.
bloques_juntos$ReactionTimes<-1/(bloques_juntos$ReactionTimes)

#contrastes para la variable Relacion Semantica. Contrasta Fuerte y debil contra No, y despues fuerte y debil entre sí.
contrasts(bloques_juntos$RelacionSemantica)<-cbind(c(1,1,-2), c(1,-1,0))
#contrastes para bloques no se si esta bien. No estaba seguro como contrastarlos
contrasts(bloques_juntos$Bloque)<-cbind(c(1,1,-1,-1),c(1,-1,0,0),c(0,0,1,-1))

library(nlme)
#armado de los modelos para el anova como modelo lineal general
#modelo para RT solo
modelRTbloque<- lme(ReactionTimes~1, random=~1|NumSujeto/RelacionSemantica/Bloque, data=bloques_juntos, method="ML")
#modelo RT con Relacion
modelRelacionbloque<-lme(ReactionTimes~RelacionSemantica, random=~1|NumSujeto/RelacionSemantica/Bloque, data=bloques_juntos, method="ML")
#modelo para bloques
modelBloque <- update(modelRelacionbloque, .~. +Bloque)
#modelo interaccion bloque vs relacion
modelInterbloque <- update(modelBloque,.~. +RelacionSemantica:Bloque)
#anovas de interes
anova(modelRTbloque, modelRelacionbloque,modelBloque,modelInterbloque)
anova(modelInterbloque)

#tuckey post hoc!!! Primero para reacion, despues para bloque
library(multcomp)
summary(glht(modelRelacionbloque, linfct = mcp(RelacionSemantica = "Tukey")))
summary(glht(modelBloque, linfct = mcp(Bloque = "Tukey")))
summary(glht(modelInterbloque, linfct = mcp(Bloque = "Tukey")))



anova.bloques<-ezANOVA(data=bloques_juntos, dv= ReactionTimes, wid= .(NumSujeto), within=.(RelacionSemantica, Bloque), detailed = TRUE, type = 2)
anova.bloques


```

#Tarea de visualización Objetiva
```{R d prime}
#llamo librerias
library(ggplot2)
library(psych)

#lugar donde tengo guardado los aarchivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv. Importante fill=True
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de visualización del prime que van de la fila 322 a 450
  visualizacion.total<- resultado.crudo[322:450,]

})


#une para todos los sujetos los ensayos de visualización en un solo dataFrame
visualizacion.total<-Reduce(function(x,y){merge(x,y,all=TRUE)}, data.set)

#listas de los animales y objetos pertenecientes a los estímulos Prime  
animales_prime <- c("oveja", "raton", "burro", "araña", "perro", "abeja", "gorila", "aguila","jirafa", "sapo","cisne", "hormiga", "zorrino", "mosca", "tigre", "escarabajo", "cocodrilo",	"gallo", "ciervo", "rinoceronte", "ardilla", "mariposa", "conejo",	"pinguino", "chancho", "tortuga", "elefante", "canguro", "avestruz", "camello", "gallina", "oso")

objetos_prime <- c("jarra",	"taza", "serrucho",	"bowl", "sobre", "tuerca", "cama",	"puerta", "candado", "ventana", "copa",	"pincel","pava",	"lapiz", "tijera",	"escritorio","pipa",	"cuchara", "cuchillo",	"sombrero", "botella",	"hacha", "martillo", "regla", "destornillonador", "peine", "silla", "pinza","bota",	"llave", "sarten",	"media")

#seteo las variables en 0 para el contador de respuestas correctas por sujeto  
animales.correctas <- 0 
animales.incorrectas <- 0 
objetos.correctas <- 0 
objetos.incorrectas <- 0

#df que va a contener las respuestas para cada una de las 4 posibles para la tarea de visualización
dfvisualizacion <- cbind(1:50, 0, 0,0,0)
colnames(dfvisualizacion)<- c("NumSujetos", "Animales Correctas", "Animales Incorrectas", "Objetos COrrectas", "Objetos Incorrectas")

#contador para el loop while
x=1
#x<3871 porque ya sabia que el total de respuestas era de 3871. Cambiar a lo necesario
while(x<7000){
  #extrae el numero del sujeto que está evaluando para sumarle al contador de ese sujeto
numSujeto<- as.numeric(visualizacion.total[x,1])
  #evalúa animales correctas
  if ((as.character(visualizacion.total[x,3])== as.character(1)) & (as.character(visualizacion.total[x,5]) %in% animales_prime)){
      animales.correctas = animales.correctas + 1
      #suma a la casilla de ese sujeto de animales correctas
      dfvisualizacion[numSujeto,2]<-dfvisualizacion[numSujeto,2]+1 }
  #evalúa animales incorrectas
  else if ((as.numeric(as.character(visualizacion.total[x,3])) == 0) & (as.character(visualizacion.total[x,5]) %in% animales_prime)){
      animales.incorrectas = animales.incorrectas + 1
      #suma a la casilla de ese sujeto de animales correctas
      dfvisualizacion[numSujeto,3]<-dfvisualizacion[numSujeto,3]+1 }
  #evalúa objetos correctas
  else if ((as.numeric(as.character(visualizacion.total[x,3])) == 1) & (as.character(visualizacion.total[x,5]) %in% objetos_prime)){
      objetos.correctas = objetos.correctas + 1
      #suma a la casilla de ese sujeto de objetos correctas
      dfvisualizacion[numSujeto,4]<-dfvisualizacion[numSujeto,4]+1 }
  #evalúa objetos incorrectas
  else if ((as.numeric(as.character(visualizacion.total[x,3])) == 0) & (as.character(visualizacion.total[x,5]) %in% objetos_prime)){
      objetos.incorrectas = objetos.incorrectas + 1
      #suma a la casilla de ese sujeto de objetos correctas
      dfvisualizacion[numSujeto,5]<-dfvisualizacion[numSujeto,5]+1}

#agrega uno al contador X del loop
x = x+1  
}

#divide Animales correctas por 64 para obtener el Hit Rate. Y divide por 64 a Objetos incorrectos para obtener el FA rate y agrega estas dos columnas al df. La elección de estas condiciones es casi arbitraria. Y por ultimo agarra en una última columna y le aplica la qnorm(inversa de la normal) a estas dos columnas luego las resta y así obtiene el D'.
dfvisualizacion<-cbind(dfvisualizacion, dfvisualizacion[,2]/64,  dfvisualizacion[,5]/64, (qnorm(dfvisualizacion[,2]/64)-qnorm(dfvisualizacion[,5]/64)))
colnames(dfvisualizacion)<- c("NumSujetos", "Animales Correctas", "Animales Incorrectas", "Objetos COrrectas", "Objetos Incorrectas", "HitRate","FA rate", "dprime")

#dfvisualizacion
#sujetos a descartar por visibilidad objetiva
dfvisualizacion[which(dfvisualizacion[,6] > 0.65),1]

#dfvisualizacion
describe(dfvisualizacion[,8], na.rm=TRUE)

t.test(dfvisualizacion[,8],mu=0 )

```


#Tarea de visualización Subjetiva
```{R visualización subjetiva}
library(psych)
#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv. Importante fill=True
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de visualización del prime que van de la fila 322 a 450
  visualizacion.total<- resultado.crudo[299,]

})


#une para todos los sujetos la parte de  visualización subjetiva en un solo dataFrame
visualizacion.subjetiva<-Reduce(function(x,y){merge(x,y,all=TRUE)}, data.set)
visualizacion.subjetiva
describe(as.numeric(as.character(visualizacion.subjetiva[,3])))


```



#Delta Analysis
```{R Delta Analysis}
Delta_SOA_66 <- cbind(meansxSujetos$Sujetos,"SOA_66", (meansxSujetos$NR - meansxSujetos$SR), (meansxSujetos$NR - meansxSujetos$WR))

Delta_SOA_66 <- as.data.frame(Delta_SOA_66)

colnames(Delta_SOA_66) <- c("Sujetos","Estimulo","FR-NR", "DR-NR")

Delta_SOA_66$`FR-NR`<- as.numeric(as.character(Delta_SOA_66$`FR-NR`))

describe(Delta_SOA_66$`FR-NR`)


```
#Analysis by item
```{R Analysis by item, eval=FALSE, include=FALSE}
library(tidyr)
total.unido <- unite(total.Sinos, "Prime_Target", c(Prime, Target), sep = "_")

#promedia los RT de todos los sujetos por par en lugar de por sujeto como hacia siempre
by.item <- aggregate(total.unido$Tiempo, by = list(Item = total.unido$Prime_Target), mean)

#une los pares
pares <-read.csv("C:/Users/Profe/Google Drive/Análisis Datos Priming/Pares de estímulos.csv", header = FALSE, sep=";", dec=".")
pares_unidos <- unite(pares, "Prime_Target", c(V1, V2), sep = "_")
pares_unidos<- tolower(pares_unidos$Prime_Target)

#agrupa los pares para cada variable
strong <- cbind(pares_unidos[1:16], 0, "SR")
colnames(strong) <- c("pares", "RT", "condicion")
weak <- cbind(pares_unidos[17:32],0, "WR")
colnames(weak) <- c("pares", "RT","condicion")
not <- cbind(pares_unidos[33:64],0, "NR")
colnames(not) <- c("pares", "RT", "condicion")

#asigna el RT para cada par de cada condicion (no se porque lo hice tan complicado)
x=1
while(x < 17){
  strong[x, 2] <- as.numeric(as.character(by.item[which(as.character(strong[x, 1]) == as.character(by.item[,1])),2]))
  x = x + 1}
x=1
while(x < 17){
  weak[x, 2] <- as.numeric(as.character(by.item[which(as.character(weak[x, 1]) == as.character(by.item[,1])),2]))
  x = x + 1}
x=1
while(x < 33){
  not[x, 2] <- as.numeric(as.character(by.item[which(as.character(not[x, 1]) == as.character(by.item[,1])),2]))
  x = x + 1}

#agrupa las 3 condiciones en un data frame
paresAnova <- as.data.frame(rbind(strong, weak, not))
paresAnova$RT<- as.numeric(as.character(paresAnova$RT))

#prueba de levene homogeneidad de la varianza
leveneTest(paresAnova$RT, paresAnova$condicion, center = median)

#ANOVA de una via para analisis by item
byitemModel <- aov(RT~condicion, data = paresAnova)

summary(byitemModel)

```
#Relación semántica
```{R relacion semantica entre estimulos, echo=TRUE}

#levanta el csv donde están guardado los 64 pares de estímulos
pares<-cbind(read.csv("C:/Users/Profe/Google Drive/Análisis Datos Priming/Pares de estímulos.csv", header = FALSE, sep=";", dec="."),0,0)
colnames(pares) <- c("Prime", "Target", "Likert_Pre","Likert_Post")
library(tidyr)
p.unidos_SOA_66<- unite(pares, "Prime_Target", c(Prime, Target), sep = "_")
p.unidos_SOA_66$Prime_Target<- tolower(p.unidos_SOA_66$Prime_Target)


#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)
data.set <- lapply(files, function(x){
  #`abre el csv. Importante fill=True
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Prime", "Target", "Respuesta", "Prime", "Target", "x", "x", "x", "x"), fill = TRUE)
  #se queda la parte de resultados de la tarea de visualización del prime que van de la fila 322 a 450
  pares.relacion<- resultado.crudo[452:515,0:4]

})

#une para todos los sujetos la parte de las respuestas sobre los 64 pares en un solo dataFrame
pares.relacion<-Reduce(function(x,y){merge(x,y,all=TRUE)}, data.set)
library(tidyr)
paresunidos <- unite(pares.relacion, "Prime_Target",c(Prime, Target))

x=0
while(x<3000){
  p <- paresunidos[x,]
  
  p.unidos_SOA_66[which(p[,2]==p.unidos_SOA_66[,1]),3]=as.numeric(as.character(p[,3])) + as.numeric(as.character(p.unidos_SOA_66[which(p[,2] == p.unidos_SOA_66[,1]), 3]))

  x=x+1
  
}

p.unidos_SOA_66$Likert_Post = p.unidos_SOA_66$Likert_Post / length(unique(paresunidos$NumSujeto))



```

#Cluster Analysis
```{r Clusters, eval=FALSE, include=FALSE}

#Levanta los archivos armados para cada cluster
cluster1 <- read.csv("C:/Users/nico_/Documents/Scripts R/Clusters/Proyecto SOA/SOA 66/Cluster 7-5.5.csv", header = FALSE, sep=";", dec=",", col.names= c("Par", "Likert"))
cluster1$Par <- tolower(cluster1$Par) 

cluster2 <- read.csv("C:/Users/nico_/Documents/Scripts R/Clusters/Palabras/Cluster 5.5-4.csv", header = FALSE, sep=";", dec=",", col.names= c("Par", "Likert"))
cluster2$Par <- tolower(cluster2$Par)
cluster3 <- read.csv("C:/Users/nico_/Documents/Scripts R/Clusters/Palabras/Cluster 4-2.5.csv", header = FALSE, sep=";", dec=",", col.names= c("Par", "Likert"))
cluster3$Par <- tolower(cluster3$Par)
cluster4 <- read.csv("C:/Users/nico_/Documents/Scripts R/Clusters/Palabras/Cluster 2.5-1.csv", header = FALSE, sep=";", dec=",", col.names= c("Par", "Likert"))
cluster4$Par <- tolower(cluster4$Par)



library(tidyr)
totalUnidos <- unite(total.Sinos, "Prime_Target",c(Prime, Target))

c1 <- subset(totalUnidos, totalUnidos[,5]%in%cluster1[,1])
c2 <- subset(totalUnidos, totalUnidos[,5]%in%cluster2[,1])
c3 <- subset(totalUnidos, totalUnidos[,5]%in%cluster3[,1])
c4 <- subset(totalUnidos, totalUnidos[,5]%in%cluster4[,1])

clusters<-cbind(aggregate(c1$Tiempo, by=list(Sujetos = c1$NumSujeto), mean),aggregate(c2$Tiempo, by=list(Sujetos = c2$NumSujeto), mean)[,2],aggregate(c3$Tiempo, by=list(Sujetos = c3$NumSujeto), mean)[,2],aggregate(c4$Tiempo, by=list(Sujetos = c4$NumSujeto), mean)[,2])
colnames(clusters)<-c("Sujetos", "c1", "c2", "c3", "c4")

library(psych)
describe(c1$Tiempo)
describe(c2$Tiempo)
describe(c3$Tiempo)
describe(c4$Tiempo)

library(reshape)
cluster_Melt_SOA_66 <- melt(clusters, id=c("Sujetos"))
colnames(cluster_Melt_SOA_66)<-c("Sujetos","cluster", "RT")
cluster_Melt_SOA_66$tiempo <- 1/cluster_Melt_SOA_66[,3]

contrasts(cluster_Melt_SOA_66$cluster)<- cbind(c(1,1,-1,-1), c(1,-1,0,0), c(0,0,-1,1))

library(nlme)

#armado de los modelos para el anova como modelo lineal general
#modelo para RT solo
modelRTc<- lme(RT~1, random=~1|Sujetos, data=cluster_Melt_SOA_66, method="ML")
#modelo RT con Relacion
modelRelacionC<-lme(RT~cluster, random=~1|Sujetos/cluster, data=cluster_Melt_SOA_66, method="ML")
anova(modelRTc, modelRelacionC)
anova(modelRelacionC)


library(ez)
#anova con ezANOVA, más simple
anova<-ezANOVA(data=cluster_Melt_SOA_66, dv= RT, wid= .(Sujetos), within=cluster, detailed = TRUE, type = 2)
anova

#tuckey post hoc!!! Necesita un modelo lineal.
library(multcomp)
posthocs <- glht(modelRelacionC, linfct = mcp(cluster = "Tukey"))
summary(posthocs)



```

#Puntaje Z
```{R Puntaje Z}

#working directory, donde se guardan los graficos
setwd("C:/Users/Profe/Google Drive/Análisis Datos Priming")

#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv 
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de Priming enmascarado que van de la fila 41 a la 296
  resultado.cortado<- resultado.crudo[41:296,]
  
  #se queda solo con las respuestas correctas y las columnas de interés
  resultado.correctas<-subset(resultado.cortado, resultado.cortado[,3] == 1, select=c("NumSujeto","Trial", "Tiempo", "Categoria", "Prime", "Target"))
  
  #convierte en numeric a los TR sino los toma como Factors. Primero se convierten character y después en numeric 
  resultado.correctas$Tiempo<-as.numeric(as.character(resultado.correctas$Tiempo))
  resultado.correctas$Trial<-as.numeric(as.character(resultado.correctas$Trial))
  #elimina outliers que estén a mas de 2.5 SD de la media de cada Sujeto en respuestas correctas.
  sinOutliers <- subset(resultado.correctas, resultado.correctas[,3] > mean(resultado.correctas[,3])-2.5*sd(resultado.correctas[,3]) & resultado.correctas[,3] < mean(resultado.correctas[,3])+2.5*sd(resultado.correctas[,3]))

transformacionZ <- sinOutliers  
transformacionZ$Tiempo <- scale(transformacionZ$Tiempo, center = TRUE, scale = TRUE)
transformacionZ
  
})

#une los TR de NR de todos los sujetos en un solo dataFrame
totalZ<- Reduce(function(x,y) {merge(x,y,all=TRUE)}, data.set)

meanTotal<-aggregate(totalZ$Tiempo, by=list(Sujetos = totalZ$NumSujeto), mean)

#crea DF para correctas Strong Related
correctasSRZ<- subset(totalZ,totalZ[,4] == "sra" |totalZ[,4] == "sro" )
meanSRZ <- aggregate(correctasSRZ$Tiempo,  by=list(Sujetos = correctasSRZ$NumSujeto), mean)
colnames(meanSRZ) <- c("Sujeto", "RT")

#crea DF para correctas Weakly Related
correctasWRZ<- subset(totalZ,totalZ[,4] == "wra" |totalZ[,4] == "wro" )
meanWRZ <- aggregate(correctasWRZ$Tiempo,  by=list(Sujetos = correctasWRZ$NumSujeto), mean)
colnames(meanWRZ) <- c("Sujeto", "RT")

#crea DF para correctas Not Related
correctasNRZ<- subset(totalZ,totalZ[,4] == "nr")
meanNRZ <- aggregate(correctasNRZ$Tiempo,  by=list(Sujetos = correctasNRZ$NumSujeto), mean)
colnames(meanNRZ) <- c("Sujeto", "RT")

#Une las 3 medias por sujetos en un solo DF
means_SOA_66Z<-cbind(meanSRZ, meanWRZ$RT, meanNRZ$RT)
colnames(means_SOA_66Z) <- c("Sujetos", "Strong Related", "Weakly Related", "Not Related")


#meltea invTr para poder graficar anova etc. Tiene que estar long no wide
library(reshape)
melt_SOA_66Z <- melt(means_SOA_66Z, id=c("Sujetos"))
melt_SOA_66Z$Sujetos<-as.character(melt_SOA_66Z$Sujetos)
colnames(melt_SOA_66Z) <- c("Sujetos", "Relacion", "RT")
   

#normalidad Shapiro-Wilk
shapiro.test(melt_SOA_66Z$RT)
                                  
library(ez); library(multcomp); library(nlme); library(pastecs); library(reshape); library(WRS2)
#contrastes para la variable Relacion Semantica. Contrasta Fuerte y debil contra No, y despues fuerte y debil entre sí.
contrasts(melt_SOA_66Z$Relacion)<- cbind(c(1,1,-2), c(1,-1,0))

library(nlme)
#armado de los modelos para el anova como modelo lineal general
#modelo para RT solo
modelRT<- lme(RT~1, random=~1|Sujetos, data=melt_SOA_66Z, method="ML")
#modelo RT con Relacion
modelRelacionZ<-lme(RT~Relacion, random=~1|Sujetos/Relacion, data=melt_SOA_66Z, method="ML")

anova(modelRT, modelRelacionZ)
anova(modelRelacionZ)



#anova con ezANOVA, más simple
anova<-ezANOVA(data=melt_SOA_66Z, dv= RT, wid= .(Sujetos), within=Relacion, detailed = TRUE, type = 2)
anova

#tuckey post hoc!!! Necesita un modelo lineal.
library(multcomp)
posthocs <- glht(modelRelacionZ, linfct = mcp(Relacion = "Tukey"))
summary(posthocs)

#bonferroni post hoc
pairwise.t.test(melt_SOA_66Z$RT, melt_SOA_66Z$Relacion, paired = TRUE, p.adjust.methods = "bonferroni")


```
#Analisis por categoría
```{R Analisis categoria}
#working directory, donde se guardan los graficos
path = ("C:/Users/Profe/Google Drive/Análisis Datos Priming")
setwd(path)

#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv 
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de Priming enmascarado que van de la fila 41 a la 296
  resultado.cortado<- resultado.crudo[41:296,]
  
  #se queda solo con las respuestas correctas y las columnas de interés
  resultado.correctas<-subset(resultado.cortado, resultado.cortado[,3] == 1, select=c("NumSujeto","Trial", "Tiempo", "Categoria", "Prime", "Target"))
  
  #convierte en numeric a los TR sino los toma como Factors. Primero se convierten character y después en numeric 
  resultado.correctas$Tiempo<-as.numeric(as.character(resultado.correctas$Tiempo))
  resultado.correctas$Trial<-as.numeric(as.character(resultado.correctas$Trial))
  #elimina outliers que estén a mas de 2.5 SD de la media de cada Sujeto en respuestas correctas.
  sinOutliers <- subset(resultado.correctas, resultado.correctas[,3] > mean(resultado.correctas[,3])-2.5*sd(resultado.correctas[,3]) & resultado.correctas[,3] < mean(resultado.correctas[,3])+2.5*sd(resultado.correctas[,3]))

})

#une los TR de NR de todos los sujetos en un solo dataFrame
total<- Reduce(function(x,y) {merge(x,y,all=TRUE)}, data.set)
#total$Tiempo <- log10(total$Tiempo)
#levanta CSV con estimulos
stim <- read.csv("C:/Users/Profe/Google Drive/Análisis Datos Priming/estimulos.csv", header = FALSE, sep=";", dec=".")
colnames(stim) <- c("animales_prime", "animales_target", "objetos_prime", "objetos_target")
                 
#crea DF para correctas Strong Related Animals
correctasSRA<- subset(total,total[,4] == "sra")
meanSRA <- aggregate(correctasSRA$Tiempo,  by=list(Sujetos = correctasSRA$NumSujeto), mean)
colnames(meanSRA) <- c("Sujeto", "RT")
#crea DF para correctas Weakly Related Animals
correctasWRA<- subset(total,total[,4] == "wra")
meanWRA <- aggregate(correctasWRA$Tiempo,  by=list(Sujetos = correctasWRA$NumSujeto), mean)
colnames(meanWRA) <- c("Sujeto", "RT")
#crea DF para correctas Not Related Animals
correctasNRA<- subset(total,total[,4] == "nr" & (total[,6] %in% tolower(stim$animales_target)) )
meanNRA <- aggregate(correctasNRA$Tiempo,  by=list(Sujetos = correctasNRA$NumSujeto), mean)
colnames(meanNRA) <- c("Sujeto", "RT")


#Une las 3 medias por sujetos en un solo DF
means_animales<-cbind(meanSRA, meanWRA$RT, meanNRA$RT)
colnames(means_animales) <- c("Sujetos", "Strong Related", "Weakly Related", "Not Related")


#meltea invTr para poder graficar anova etc. Tiene que estar long no wide
library(reshape)
melt_animales <- melt(means_animales, id=c("Sujetos"))
melt_animales$Sujetos<-as.character(melt_animales$Sujetos)
colnames(melt_animales) <- c("Sujetos", "Relacion", "RT")
           
#shapiro wilk
shapiro.test(melt_animales$RT)
                          
library(ez)
#anova con ezANOVA, más simple
anova<-ezANOVA(data=melt_animales, dv= RT, wid= (Sujetos), within=Relacion, detailed = TRUE, type = 3)
anova

library(nlme)
#armado de los modelos para el anova como modelo lineal general
#modelo para RT solo
modelRT<- lme(RT~1, random=~1|Sujetos, data=melt_animales, method="ML")
#modelo RT con Relacion
modelRelacionAnimales<-lme(RT~Relacion, random=~1|Sujetos/Relacion, data=melt_animales, method="ML")

anova(modelRT, modelRelacionAnimales)
anova(modelRelacionAnimales)

#bonferroni post hoc
pairwise.t.test(melt_animales$RT, melt_animales$Relacion, paired = TRUE, p.adjust.methods = "bonferroni")

#crea DF para correctas Strong Related Animals
correctasSRO<- subset(total,total[,4] == "sro")
meanSRO <- aggregate(correctasSRO$Tiempo,  by=list(Sujetos = correctasSRO$NumSujeto), mean)
colnames(meanSRO) <- c("Sujeto", "RT")
#crea DF para correctas Weakly Related Animals
correctasWRO<- subset(total,total[,4] == "wro")
meanWRO <- aggregate(correctasWRO$Tiempo,  by=list(Sujetos = correctasWRO$NumSujeto), mean)
colnames(meanWRO) <- c("Sujeto", "RT")
#crea DF para correctas Not Related Animals
correctasNRO<- subset(total,total[,4] == "nr" & (total[,6] %in% tolower(stim$objetos_target)) )
meanNRO <- aggregate(correctasNRO$Tiempo,  by=list(Sujetos = correctasNRO$NumSujeto), mean)
colnames(meanNRO) <- c("Sujeto", "RT")

#Une las 3 medias por sujetos en un solo DF
means_objetos<-cbind(meanSRO, meanWRO$RT, meanNRO$RT)
colnames(means_objetos) <- c("Sujetos", "Strong Related", "Weakly Related", "Not Related")

#meltea invTr para poder graficar anova etc. Tiene que estar long no wide
library(reshape)
melt_objetos <- melt(means_objetos, id=c("Sujetos"))
melt_objetos$Sujetos<-as.character(melt_objetos$Sujetos)
colnames(melt_objetos) <- c("Sujetos", "Relacion", "RT")
         

#shapiro wilk
shapiro.test(melt_objetos$RT)

library(ez)
#anova con ezANOVA, más simple
ezANOVA(data=melt_objetos, dv= RT, wid= .(Sujetos), within=Relacion, detailed = TRUE, type = 2)

library(nlme)
#armado de los modelos para el anova como modelo lineal general
#modelo para RT solo
modelRT<- lme(RT~1, random=~1|Sujetos, data=melt_objetos, method="ML")
#modelo RT con Relacion
modelRelacionobjetos<-lme(RT~Relacion, random=~1|Sujetos/Relacion, data=melt_objetos, method="ML")

anova(modelRT, modelRelacionobjetos)
anova(modelRelacionobjetos)

#bonferroni post hoc
pairwise.t.test(melt_objetos$RT, melt_objetos$Relacion, paired = TRUE, p.adjust.methods = "bonferroni")
```
#Analysis without bad pairs
```{R Without bad ones}
#working directory, donde se guardan los graficos
path = ("C:/Users/Profe/Google Drive/Análisis Datos Priming")
setwd(path)

#lugar donde tengo guardado los archivos
my.path <- "C:/Users/Profe/Google Drive/Análisis Datos Priming/Proyecto SOA/SOA 66"

#levanta todos los archivos de la carpeta que sean .csv
files <- list.files(path=my.path, pattern="*.csv", full.names=TRUE, recursive=FALSE)

#levanta todos los archivos en la carpeta y le aplica la función
data.set <- lapply(files, function(x){
  #`abre el csv 
resultado.crudo  <-read.csv(x, header = FALSE, sep=",", dec=".", col.names= c("NumSujeto", "Trial", "CalidaddeRespuesta", "Tiempo", "Prime", "Target", "Categoria", "Tecla presionada", "Tecla para responder afirmativamente", "Tiempo de apariciÃ³n del prime"), fill = TRUE)
  #se queda la parte de resultados de la tarea de Priming enmascarado que van de la fila 41 a la 296
  resultado.cortado<- resultado.crudo[41:296,]
  
  #se queda solo con las respuestas correctas y las columnas de interés
  resultado.correctas<-subset(resultado.cortado, resultado.cortado[,3] == 1, select=c("NumSujeto","Trial", "Tiempo", "Categoria", "Prime", "Target"))
  
  #convierte en numeric a los TR sino los toma como Factors. Primero se convierten character y después en numeric 
  resultado.correctas$Tiempo<-as.numeric(as.character(resultado.correctas$Tiempo))
  resultado.correctas$Trial<-as.numeric(as.character(resultado.correctas$Trial))
  #elimina outliers que estén a mas de 2.5 SD de la media de cada Sujeto en respuestas correctas.
  sinOutliers <- subset(resultado.correctas, resultado.correctas[,3] > mean(resultado.correctas[,3])-2.5*sd(resultado.correctas[,3]) & resultado.correctas[,3] < mean(resultado.correctas[,3])+2.5*sd(resultado.correctas[,3]))

})

library(tidyr)
#une los TR de NR de todos los sujetos en un solo dataFrame
total<- Reduce(function(x,y) {merge(x,y,all=TRUE)}, data.set)
total$Tiempo <- 1/total$Tiempo 
total.unidos <- unite(total, "Prime_Target", c(Prime, Target), sep = "_")


bad_pairs <- read.csv("C:/Users/Profe/Google Drive/Análisis Datos Priming/Pares malos.csv", sep = ";")
colnames(bad_pairs) <-c("Palabras", "SOA_66", "Relacion")
bad_pairs$Palabras <- tolower(bad_pairs$Palabras)

sin_bad <- subset(total.unidos, !(Prime_Target %in% bad_pairs$SOA_66)) 

correctasSR.Sinbad <- subset(sin_bad,sin_bad[,4] == "sra" |sin_bad[,4] == "sro" )
meanSRsinbad <-  aggregate(correctasSR.Sinbad$Tiempo, by=list(Sujetos = correctasSR.Sinbad$NumSujeto), mean )
colnames(meanSRsinbad) <- c("Sujetos", "RT")
#crea DF para correctas Weakly Related
correctasWR.Sinbad<- subset(sin_bad,sin_bad[,4] == "wra" |sin_bad[,4] == "wro" )
meanWRsinbad <-  aggregate(correctasWR.Sinbad$Tiempo, by=list(Sujetos = correctasWR.Sinbad$NumSujeto), mean )
colnames(meanWRsinbad) <- c("Sujetos", "RT")
#crea DF para correctas Not Related
correctasNR.Sinbad<- subset(sin_bad,sin_bad[,4] == "nr")
meanNRsinbad <-  aggregate(correctasNR.Sinbad$Tiempo, by=list(Sujetos = correctasNR.Sinbad$NumSujeto), mean )
colnames(meanNRsinbad) <- c("Sujetos", "RT")

#Une las 3 medias por sujetos en un solo DF
means_sinbad<-cbind(meanSRsinbad, meanWRsinbad$RT, meanNRsinbad$RT)
colnames(means_sinbad) <- c("Sujetos", "Strong Related", "Weakly Related", "Not Related")

#meltea invTr para poder graficar anova etc. Tiene que estar long no wide
library(reshape)
melt_sinbad <- melt(means_sinbad, id=c("Sujetos"))
melt_sinbad$Sujetos<-as.character(melt_sinbad$Sujetos)
colnames(melt_sinbad) <- c("Sujetos", "Relacion", "RT")
         

#shapiro wilk
shapiro.test(melt_sinbad$RT)

library(ez)
#anova con ezANOVA, más simple
ezANOVA(data=melt_sinbad, dv= RT, wid= .(Sujetos), within=Relacion, detailed = TRUE, type = 2)

library(nlme)
#armado de los modelos para el anova como modelo lineal general
#modelo para RT solo
modelRT<- lme(RT~1, random=~1|Sujetos, data=melt_sinbad, method="ML")
#modelo RT con Relacion
modelRelacionsinbad<-lme(RT~Relacion, random=~1|Sujetos/Relacion, data=melt_sinbad, method="ML")

anova(modelRT, modelRelacionsinbad)
anova(modelRelacionsinbad)

#bonferroni post hoc
pairwise.t.test(melt_sinbad$RT, melt_sinbad$Relacion, paired = TRUE, p.adjust.methods = "bonferroni")



```